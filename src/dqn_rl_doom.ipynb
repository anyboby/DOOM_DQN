{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf      # Deep Learning library\n",
    "import numpy as np           # Handle matrices\n",
    "from vizdoom import *        # Doom Environment\n",
    "\n",
    "import random                # Handling random number generation\n",
    "import time                  # Handling time calculation\n",
    "from skimage import transform# Help us to preprocess the frames\n",
    "\n",
    "from collections import deque# Ordered collection with ends\n",
    "import matplotlib.pyplot as plt # Display graphs\n",
    "\n",
    "import warnings # This ignore all the warning messages that are normally printed during the training because of skiimage\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Create our environment üéÆ\n",
    "\n",
    "A monster is spawned randomly somewhere along the opposite wall.\n",
    "Player can only go left/right and shoot.\n",
    "1 hit is enough to kill the monster.\n",
    "Episode finishes when monster is killed or on timeout (300). \n",
    "\n",
    "REWARDS:\n",
    "\n",
    "+101 for killing the monster\n",
    "\n",
    "-5 for missing\n",
    "Episode ends after killing the monster or on timeout.\n",
    "living reward = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Here we create our environment\n",
    "\"\"\"\n",
    "def create_environment():\n",
    "    game = DoomGame()\n",
    "    \n",
    "    # Load the correct configuration\n",
    "    game.load_config(\"basic.cfg\")\n",
    "    \n",
    "    # Load the correct scenario (in our case basic scenario)\n",
    "    game.set_doom_scenario_path(\"basic.wad\")\n",
    "    \n",
    "    game.init()\n",
    "    \n",
    "    # Here our possible actions\n",
    "    left = [1, 0, 0]\n",
    "    right = [0, 1, 0]\n",
    "    shoot = [0, 0, 1]\n",
    "    possible_actions = [left, right, shoot]\n",
    "    \n",
    "    return game, possible_actions\n",
    "\n",
    "\"\"\"\n",
    "Here we perform random actions to test the environment\n",
    "\"\"\"\n",
    "def test_environment():\n",
    "    game = DoomGame()\n",
    "    game.load_config(\"basic.cfg\")\n",
    "    game.set_doom_scenario_path(\"basic.wad\")\n",
    "    game.init()\n",
    "    shoot = [0,0,1]\n",
    "    left = [1,0,0]\n",
    "    right = [0,1,0]\n",
    "    actions = [shoot, left, right]\n",
    "    \n",
    "    episodes = 10\n",
    "    for i in range(episodes):\n",
    "        game.new_episode()\n",
    "        while not game.is_episode_finished():\n",
    "            state = game.get_state()\n",
    "            img = state.screen_buffer\n",
    "            misc = state.game_variables\n",
    "            action = random.choice(actions)\n",
    "            print(action)\n",
    "            rewards = game.make_action(action)\n",
    "            print(\"\\treward:\", reward)\n",
    "            time.sleep(0.02)\n",
    "        print(\"Result: \", game.get_total_reward)\n",
    "        time.sleep(2)\n",
    "    game.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "game, possible_actions = create_environment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "    preprocess_frame:\n",
    "    Take a frame.\n",
    "    Resize it.\n",
    "        __________________\n",
    "        |                 |\n",
    "        |                 |\n",
    "        |                 |\n",
    "        |                 |\n",
    "        |_________________|\n",
    "        \n",
    "        to\n",
    "        _____________\n",
    "        |            |\n",
    "        |            |\n",
    "        |            |\n",
    "        |____________|\n",
    "    Normalize it.\n",
    "    \n",
    "    return preprocessed_frame\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "def preprocess_frame(frame):\n",
    "    #greyscale frame already done in our vizdoom config\n",
    "    #x = np.mean(frame, -1)\n",
    "    \n",
    "    #crop the screen (remove the roof because it contains no information)\n",
    "    cropped_frame = frame[30:-10,30:-30]\n",
    "    \n",
    "    #normalize pixel values\n",
    "    normalized_frame = cropped_frame/255.0\n",
    "    \n",
    "    #resize\n",
    "    preprocessed_frame = transform.resize(normalized_frame, [84,84])\n",
    "    return preprocessed_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stack frames\n",
    "\n",
    "Stacking frames is really important because it helps us to give have a sense of motion to our Neural Network.\n",
    "\n",
    "-First we preprocess frame\n",
    "-Then we append the frame to the deque that automatically removes the oldest frame\n",
    "-Finally we build the stacked state\n",
    "\n",
    "This is how work stack:\n",
    "\n",
    "-For the first frame, we feed 4 frames\n",
    "-At each timestep, we add the new frame to deque and then we stack them to form a new stacked frame\n",
    "-And so on stack\n",
    "-If we're done, we create a new stack with 4 new frames (because we are in a new episode)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_size = 4  #4 frames in a stack\n",
    "\n",
    "#init deque with zero images one array for each image\n",
    "stacked_frames = deque([np.zeros((84,84), dtype=np.int) for i in range(stack_size)], maxlen = 4)\n",
    "\n",
    "def stacked_frames(stacked_frames, state, is_new_episode):\n",
    "    #preprocess frame\n",
    "    frame = preprocess_frame(state)\n",
    "    \n",
    "    if is_new_episode:\n",
    "        #clear our stacked frames\n",
    "        stacked_frames = deque([np.zeros((84,84), dtype=np.int) for i in range(stack_size)], maxlen=4)\n",
    "        \n",
    "        #since its a new episode the first frame is copied 4 times\n",
    "        stacked_frames.append(frame)\n",
    "        stacked_frames.append(frame)\n",
    "        stacked_frames.append(frame)\n",
    "        stacked_frames.append(frame)\n",
    "        \n",
    "        #stack the frames\n",
    "        stacked_state = np.stack(stacked_frames, axis = 2)\n",
    "        \n",
    "    else: \n",
    "        #append frame to deque, automaticall removes the oldest frame\n",
    "        stacked_frames.append(frame)\n",
    "            \n",
    "        #build the stacked state (first dimension specifies different frames\n",
    "        stacked_state = np.stack(stacked_frames, axis = 2)\n",
    "            \n",
    "\n",
    "    return stacked_state, stacked_frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Set up our hyperparameters ‚öóÔ∏è\n",
    "In this part we'll set up our different hyperparameters. But when you implement a Neural Network by yourself you will not implement hyperparamaters at once but progressively.\n",
    "\n",
    "First, you begin by defining the neural networks hyperparameters when you implement the model.\n",
    "Then, you'll add the training hyperparameters when you implement the training algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MODEL HYPERPARAMETERS\n",
    "state_size = [84, 84, 4]    #input is stack of 4 frames witzh 84x84 pixels each\n",
    "action_size = game.get_available_buttons_size()   #should be 3 possible actions: left right shoot\n",
    "learning_rate = 0.0002      #alpha / learning rate\n",
    "\n",
    "### TRAINING HYPERPARAMETERS\n",
    "total_episodes = 500\n",
    "max_steps = 100\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "# Exploration parameters for epsilon greedy strategy\n",
    "explore_start = 1.0   # exploratio p√ºrobabaility at start\n",
    "explore_stop = 0.01   # minimum exploration probability\n",
    "decay_rate = 0.0001   # exponential decay rate for exploration prob\n",
    "\n",
    "#Q Learning hyperparameters\n",
    "gamma = 0.95     # Discounting rate\n",
    "\n",
    "\n",
    "### MEMORY HYPERPARAMETERS\n",
    "pretrain_length = batch_size   # Number of experiences stored in the Memory when initialized for the first time\n",
    "memory_size = 1000000          # Number of experiences the Memory can keep\n",
    "\n",
    "\n",
    "### MODIFY THIS TO FALSE IF YOU JUST WANT OT SEE THE TRAINED AGENT\n",
    "training = True\n",
    "\n",
    "\n",
    "## TURN THIS TO TRUE IF YOU WANT TO RENDER THE ENVIRONMENT\n",
    "episode_render = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: Create our Deep Q-learning Neural Network model üß†\n",
    "Model This is our Deep Q-learning model:\n",
    "\n",
    "-We take a stack of 4 frames as input\n",
    "\n",
    "-It passes through 3 convnets\n",
    "\n",
    "-Then it is flatened\n",
    "\n",
    "-Finally it passes through 2 FC layers\n",
    "\n",
    "-It outputs a Q value for each actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNetwork:\n",
    "    def __init__(self, state_size, action_size, learning_rate, name = 'DQNetwork'):\n",
    "            self.state_size = state_size\n",
    "            self.action_size = action_size\n",
    "            self.learning_rate = learning_rate\n",
    "            \n",
    "            with tf.variable_scope(name):\n",
    "                # we create the palceholders\n",
    "                # *state_size means that we take each elements of state_size in tuple hence is like if we wrote\n",
    "                # [None, 84, 84, 4]\n",
    "                self.inputs_ = tf.placeholder(tf.float32, [None, *state_size], name = \"inputs\")\n",
    "                self.actions_ = tf.placeholder(tf.float32, [None, 3], name = \"actions_\")\n",
    "                \n",
    "                # Remember that target_Q us the R(s,a) + ymax Qhat(s', a')\n",
    "                self.target_Q = tf.placeholder(tf.float32, [None], name = \"target\")\n",
    "                \n",
    "                \"\"\"\n",
    "                First convnet:\n",
    "                CNN\n",
    "                BatchNormalization\n",
    "                ELU\n",
    "                \"\"\"\n",
    "                \n",
    "                #Input is 84x84\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 's' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-96176b489c27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 's' is not defined"
     ]
    }
   ],
   "source": [
    "s\n",
    "s\n",
    "s\n",
    "s\n",
    "s\n",
    "s\n",
    "s\n",
    "\n",
    "s\n",
    "s\n",
    "s\n",
    "s\n",
    "s\n",
    "s\n",
    "s\n",
    "s\n",
    "s\n",
    "s\n",
    "s\n",
    "s\n",
    "s\n",
    "s\n",
    "s\n",
    "s\n",
    "s\n",
    "s\n",
    "s\n",
    "s\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
